{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aQNnmK-f2FD",
        "outputId": "93f3b4e1-2c2d-4489-eaea-b05aac46f22e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ynhrn5a2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ynhrn5a2\n",
            "  Resolved https://github.com/openai/whisper.git to commit 6dea21fd7f7253bfe450f1e2512a0fe47ee2d258\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Collecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting tiktoken==0.3.1\n",
            "  Downloading tiktoken-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Collecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230314) (0.18.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2.27.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.10.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Collecting lit\n",
            "  Downloading lit-16.0.0.tar.gz (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 KB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (63.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2022.12.7)\n",
            "Building wheels for collected packages: openai-whisper, lit\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=796926 sha256=8187946cd59eaf01cfa8b7190e803aac9eff923f455b22539a9132c8b77cbfcd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-crx0r36j/wheels/fe/03/29/e7919208d11b4ab32972cb448bb84a9a675d92cd52c9a48341\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-16.0.0-py3-none-any.whl size=93601 sha256=08891e680b203b431ea3cdf34bcbbb787973590db7a0d7c913a4795ed2b0dfdd\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/ee/80/1520ca86c3557f70e5504b802072f7fc3b0e2147f376b133ed\n",
            "Successfully built openai-whisper lit\n",
            "Installing collected packages: lit, ffmpeg-python, triton, tiktoken, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 lit-16.0.0 openai-whisper-20230314 tiktoken-0.3.1 triton-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "source": [
        "#imports\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import whisper"
      ],
      "metadata": {
        "id": "AI_A54jxf2FG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 106MiB/s]\n"
          ]
        }
      ],
      "source": [
        "# model\n",
        "# replace with model here later\n",
        "model = whisper.load_model(\"base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n0Er8cTf2FG",
        "outputId": "e3c9f658-4e80-4885-bcb5-8687eaad9957"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transcribe audios using model\n",
        "\n",
        "dir = 'audio'\n",
        "\n",
        "transcripts = {}\n",
        "\n",
        "for filename in os.listdir(dir):\n",
        "  name = os.path.join(dir, filename)\n",
        "\n",
        "  if os.path.isfile(name):\n",
        "     if filename.endswith('.wav'):\n",
        "       result = model.transcribe(name)\n",
        "       id = filename.split('.')[0]\n",
        "       transcripts[id] = result['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKlPAB2miaBY",
        "outputId": "b2f9afb3-fa6d-4737-9998-82c686f0b41e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'84_121123_000009_000007': ' See what they have done? Cride Morrell with one hand leaning on the back of the chair and the other extending towards Valentine.',\n",
              " '84_121123_000009_000008': ' See my father, see?',\n",
              " '84_121123_000008_000004': ' Go! Do you hear?\" said Villafort, while Davenie advanced to lead Moral out.',\n",
              " '84_121123_000010_000000': ' Villafort drew back and looked with astonishment on the young man, who almost a stranger to him called Nwatiya his father.',\n",
              " '84_121123_000009_000000': ' But in less than five minutes, the staircase groaned beneath an extraordinary weight.',\n",
              " '84_121123_000008_000002': ' His glance at first wandering fixed itself upon Moral.',\n",
              " '84_121123_000008_000001': ' The terrible office he had held for 25 years had succeeded in making him more or less than man.',\n",
              " '84_121123_000008_000000': ' Villafort rose half ashamed of being surprised in such a proxism of grief.',\n",
              " '84_121123_000007_000001': ' Maximilian.',\n",
              " '84_121123_000008_000003': ' Who are you, sir?\" he asked. That forget that this is not the manner to enter a house stricken with death? Go, sir! Go! But Morale remained motionless. He could not detach his eyes from that disordered bed and the pale corpse of the young girl who was lying on it.'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "transcripts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi_fs_I1f2FH",
        "outputId": "953c701b-9bb7-46e9-bf54-31cf42404395"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "source": [
        "# organize ground truths\n",
        "ground_truths = {}\n",
        "\n",
        "for filename in os.listdir(dir):\n",
        "  name = os.path.join(dir, filename)\n",
        "\n",
        "  if os.path.isfile(name):\n",
        "    if filename.endswith('.txt') and 'original' in filename:\n",
        "      id = filename.split('.')[0]\n",
        "      \n",
        "      with open(name) as txt:\n",
        "        ground_truths[id] = txt.read()"
      ],
      "metadata": {
        "id": "-9pmcpo0f2FH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'84_121123_000008_000003': '\"Who are you, sir,\" he asked, \"that forget that this is not the manner to enter a house stricken with death? Go, sir, go!\" But Morrel remained motionless; he could not detach his eyes from that disordered bed, and the pale corpse of the young girl who was lying on it.',\n",
              " '84_121123_000009_000007': '\"See what they have done!\" cried Morrel, with one hand leaning on the back of the chair, and the other extended towards Valentine.',\n",
              " '84_121123_000008_000001': 'The terrible office he had held for twenty-five years had succeeded in making him more or less than man.',\n",
              " '84_121123_000008_000004': '\"Go!--do you hear?\" said Villefort, while d\\'Avrigny advanced to lead Morrel out.',\n",
              " '84_121123_000009_000000': 'But in less than five minutes the staircase groaned beneath an extraordinary weight.',\n",
              " '84_121123_000008_000000': 'Villefort rose, half ashamed of being surprised in such a paroxysm of grief.',\n",
              " '84_121123_000010_000000': 'Villefort drew back and looked with astonishment on the young man, who, almost a stranger to him, called Noirtier his father.',\n",
              " '84_121123_000008_000002': 'His glance, at first wandering, fixed itself upon Morrel.',\n",
              " '84_121123_000009_000008': '\"See, my father, see!\"',\n",
              " '84_121123_000007_000001': 'Maximilian.'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "ground_truths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo4G_kt3f2FH",
        "outputId": "7dbdb2a7-c6fd-49c2-f70c-e6949448a9be"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['See', 'what', 'they', 'have', 'done', 'cried', 'Morrel', 'with', 'one', 'hand', 'leaning', 'on', 'the', 'back', 'of', 'the', 'chair', 'and', 'the', 'other', 'extended', 'towards', 'Valentine']\n",
            "['See', 'what', 'they', 'have', 'done', 'Cride', 'Morrell', 'with', 'one', 'hand', 'leaning', 'on', 'the', 'back', 'of', 'the', 'chair', 'and', 'the', 'other', 'extending', 'towards', 'Valentine']\n",
            "['See', 'my', 'father', 'see']\n",
            "['See', 'my', 'father', 'see']\n",
            "['Godo', 'you', 'hear', 'said', 'Villefort', 'while', 'dAvrigny', 'advanced', 'to', 'lead', 'Morrel', 'out']\n",
            "['Go', 'Do', 'you', 'hear', 'said', 'Villafort', 'while', 'Davenie', 'advanced', 'to', 'lead', 'Moral', 'out']\n",
            "['Villefort', 'drew', 'back', 'and', 'looked', 'with', 'astonishment', 'on', 'the', 'young', 'man', 'who', 'almost', 'a', 'stranger', 'to', 'him', 'called', 'Noirtier', 'his', 'father']\n",
            "['Villafort', 'drew', 'back', 'and', 'looked', 'with', 'astonishment', 'on', 'the', 'young', 'man', 'who', 'almost', 'a', 'stranger', 'to', 'him', 'called', 'Nwatiya', 'his', 'father']\n",
            "['But', 'in', 'less', 'than', 'five', 'minutes', 'the', 'staircase', 'groaned', 'beneath', 'an', 'extraordinary', 'weight']\n",
            "['But', 'in', 'less', 'than', 'five', 'minutes', 'the', 'staircase', 'groaned', 'beneath', 'an', 'extraordinary', 'weight']\n",
            "['His', 'glance', 'at', 'first', 'wandering', 'fixed', 'itself', 'upon', 'Morrel']\n",
            "['His', 'glance', 'at', 'first', 'wandering', 'fixed', 'itself', 'upon', 'Moral']\n",
            "['The', 'terrible', 'office', 'he', 'had', 'held', 'for', 'twentyfive', 'years', 'had', 'succeeded', 'in', 'making', 'him', 'more', 'or', 'less', 'than', 'man']\n",
            "['The', 'terrible', 'office', 'he', 'had', 'held', 'for', '25', 'years', 'had', 'succeeded', 'in', 'making', 'him', 'more', 'or', 'less', 'than', 'man']\n",
            "['Villefort', 'rose', 'half', 'ashamed', 'of', 'being', 'surprised', 'in', 'such', 'a', 'paroxysm', 'of', 'grief']\n",
            "['Villafort', 'rose', 'half', 'ashamed', 'of', 'being', 'surprised', 'in', 'such', 'a', 'proxism', 'of', 'grief']\n",
            "['Maximilian']\n",
            "['Maximilian']\n",
            "['Who', 'are', 'you', 'sir', 'he', 'asked', 'that', 'forget', 'that', 'this', 'is', 'not', 'the', 'manner', 'to', 'enter', 'a', 'house', 'stricken', 'with', 'death', 'Go', 'sir', 'go', 'But', 'Morrel', 'remained', 'motionless', 'he', 'could', 'not', 'detach', 'his', 'eyes', 'from', 'that', 'disordered', 'bed', 'and', 'the', 'pale', 'corpse', 'of', 'the', 'young', 'girl', 'who', 'was', 'lying', 'on', 'it']\n",
            "['Who', 'are', 'you', 'sir', 'he', 'asked', 'That', 'forget', 'that', 'this', 'is', 'not', 'the', 'manner', 'to', 'enter', 'a', 'house', 'stricken', 'with', 'death', 'Go', 'sir', 'Go', 'But', 'Morale', 'remained', 'motionless', 'He', 'could', 'not', 'detach', 'his', 'eyes', 'from', 'that', 'disordered', 'bed', 'and', 'the', 'pale', 'corpse', 'of', 'the', 'young', 'girl', 'who', 'was', 'lying', 'on', 'it']\n"
          ]
        }
      ],
      "source": [
        "# Calculate number of correct transcripts\n",
        "success = 0\n",
        "for key, text in transcripts.items():\n",
        "  truth = ground_truths[key]\n",
        "  truth_seq = re.sub('['+string.punctuation+']', '', truth).split()\n",
        "  seq = re.sub('['+string.punctuation+']','',text).split()\n",
        "  print(truth_seq)\n",
        "  print(seq)\n",
        "  if truth_seq == seq:\n",
        "    success += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9tAHDqBf2FI",
        "outputId": "e8e78135-982f-4836-c2a8-fcd70f6179f9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3\n"
          ]
        }
      ],
      "source": [
        "# Calculate accuracy\n",
        "accuracy = success / len(ground_truths.keys())\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v_xHhnuf2FI",
        "outputId": "ef249080-81fa-4098-da09-dd29d14fe1ac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notes\n",
        "- Evaluation is hard. What about slight differences?\n",
        "- Ground truths are possibly noisy."
      ],
      "metadata": {
        "id": "S3F95mmFva9t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "vP0d1tJPf2FI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "FY2cYx81f2FI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "FzUtg73Kf2FI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "SRlRKlWEf2FI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "o4pL9luNf2FI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "yQUqX9Ehf2FI"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}