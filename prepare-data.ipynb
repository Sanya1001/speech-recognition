{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "data = torchaudio.datasets.LIBRITTS(root=\"data\", url=\"train-clean-100\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pickle5\n",
      "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
      "  Building wheel for pickle5 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pickle5: filename=pickle5-0.0.11-cp310-cp310-macosx_11_0_arm64.whl size=119409 sha256=219ca2c1afd1b63ff5c64d8d86331c6f4db6af1dca9b67b2356b2f78dd8358b8\n",
      "  Stored in directory: /Users/pulljosh/Library/Caches/pip/wheels/7d/14/ef/4aab19d27fa8e58772be5c71c16add0426acf9e1f64353235c\n",
      "Successfully built pickle5\n",
      "Installing collected packages: pickle5\n",
      "Successfully installed pickle5-0.0.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pickle5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate training set (examples 0 - 3999 from dataset)\n",
    "\n",
    "This will create a file called `prepared-data/dataset_4000.pkl` which contains the first 4000 examples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping 1000 examples\n",
      "Dumping 2000 examples\n",
      "Dumping 3000 examples\n",
      "Dumping 4000 examples\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import scipy\n",
    "\n",
    "prepared_data = []\n",
    "\n",
    "for n in range(4):\n",
    "  for i in range(1000):\n",
    "    item = data[i + n * 1000]\n",
    "    waveform, sample_rate, original_text, normalized_text, speaker_id, chapter_id, utterance_id = item\n",
    "    frequencies, times, spectrogram = scipy.signal.spectrogram(waveform.squeeze(), sample_rate)\n",
    "\n",
    "    prepared_data.append({\n",
    "      \"waveform\": waveform,\n",
    "      \"spectrogram\": spectrogram,\n",
    "      \"sample_rate\": sample_rate,\n",
    "      \"original_text\": original_text,\n",
    "      \"normalized_text\": normalized_text,\n",
    "      \"speaker_id\": speaker_id,\n",
    "      \"chapter_id\": chapter_id,\n",
    "      \"utterance_id\": utterance_id\n",
    "    })\n",
    "\n",
    "  with open(\"prepared-data/dataset_4000.pkl\", \"wb\") as f:\n",
    "    print(f\"Dumping {len(prepared_data)} examples\")\n",
    "    pickle.dump(prepared_data, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate test set (examples 5000 - 5999 from dataset)\n",
    "\n",
    "This will create a file called `prepared-data/dataset_1000.pkl` which contains 1000 examples from the dataset.\n",
    "\n",
    "I am using 5000-5999 rather than 4000-4999 because when I tried 4000-4999, it failed and said the file was too big. I assume there are a few massive audio files in that range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping 1000 examples\n"
     ]
    }
   ],
   "source": [
    "prepared_data = []\n",
    "\n",
    "for i in range(1000):\n",
    "  item = data[i + 5000] # Using 5000-5999 rather than 4000-4999 because when I tried 4000-4999, it failed and said the file was too big. I assume there are a few massive audio files in there?\n",
    "  waveform, sample_rate, original_text, normalized_text, speaker_id, chapter_id, utterance_id = item\n",
    "  frequencies, times, spectrogram = scipy.signal.spectrogram(waveform.squeeze(), sample_rate)\n",
    "\n",
    "  prepared_data.append({\n",
    "    \"waveform\": waveform,\n",
    "    \"spectrogram\": spectrogram,\n",
    "    \"sample_rate\": sample_rate,\n",
    "    \"original_text\": original_text,\n",
    "    \"normalized_text\": normalized_text,\n",
    "    \"speaker_id\": speaker_id,\n",
    "    \"chapter_id\": chapter_id,\n",
    "    \"utterance_id\": utterance_id\n",
    "  })\n",
    "\n",
    "with open(\"prepared-data/dataset_1000.pkl\", \"wb\") as f:\n",
    "  print(f\"Dumping {len(prepared_data)} examples\")\n",
    "  pickle.dump(prepared_data, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: How to load the training/testing sets for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"prepared-data/dataset_1000.pkl\", \"rb\") as f:\n",
    "  testing_data = pickle.load(f)\n",
    "\n",
    "print(len(testing_data))\n",
    "\n",
    "with open(\"prepared-data/dataset_4000.pkl\", \"rb\") as f:\n",
    "  training_data = pickle.load(f)\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'waveform': tensor([[-0.0021, -0.0020, -0.0018,  ..., -0.0026, -0.0024, -0.0023]]),\n",
       " 'spectrogram': array([[6.1617322e-11, 2.4870866e-11, 1.4738427e-10, ..., 1.6959106e-11,\n",
       "         3.0114894e-10, 6.8760858e-10],\n",
       "        [2.0799680e-08, 1.8790917e-08, 1.8172292e-08, ..., 2.4452904e-08,\n",
       "         3.2318614e-08, 2.7027603e-08],\n",
       "        [4.7673461e-09, 2.5217244e-09, 6.8299362e-09, ..., 3.9812305e-09,\n",
       "         9.4678745e-09, 8.0733180e-09],\n",
       "        ...,\n",
       "        [6.7064058e-15, 8.9862013e-15, 3.6173813e-14, ..., 5.9794421e-14,\n",
       "         3.0979890e-13, 8.9270564e-15],\n",
       "        [1.0402141e-14, 1.3616231e-15, 7.5033363e-14, ..., 1.1059050e-14,\n",
       "         8.6787863e-14, 2.0568611e-14],\n",
       "        [1.6667581e-14, 1.2333496e-13, 4.6033733e-15, ..., 4.9778886e-14,\n",
       "         1.7889984e-15, 5.8257808e-14]], dtype=float32),\n",
       " 'sample_rate': 24000,\n",
       " 'original_text': \"The one was saying to the other as the weary youth lay down, 'Is there anything the least wonderful or remarkable about this neighbourhood?'\",\n",
       " 'normalized_text': \"The one was saying to the other as the weary youth lay down, 'Is there anything the least wonderful or remarkable about this neighbourhood?'\",\n",
       " 'speaker_id': 2092,\n",
       " 'chapter_id': 145706,\n",
       " 'utterance_id': '2092_145706_000012_000005'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview one of the examples\n",
    "testing_data[0]\n",
    "\n",
    "# We probably care most about spectrogram and normalized_text, but the other information is there as well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
